# build-pipeline.yml

steps:
  # --- 1. GET SERVICE NAME (Input Step) ---
  - label: "‚öôÔ∏è Select Service to Build"
    key: "get_service_name"
    prompt: "Please enter the name of the service to build."
    type: input
    fields:
      - text: "SERVICE_NAME"
        required: true

  # --- 2. BUILD AND PUSH TO ECR (Command Step) ---
  - label: "üöÄ Build & Push Docker Image for $$SERVICE_NAME"
    key: "build_and_push"
    depends_on: "get_service_name"
    commands:
      # --- LOAD ENVIRONMENT VARIABLES FROM FILE ---
      # This command loads the variables from build.env into the shell environment
      - |
        if [ -f build.env ]; then
          echo "Loading environment variables from build.env..."
          export $(grep -v '^#' build.env | xargs)
        else
          echo "Error: build.env file not found. Pipeline cannot continue."
          exit 1
        fi

      - SERVICE_NAME="emr_cluster_demo"

      # Define your ECR variables using the now-loaded shell variables
      # Note: We now use $AWS_ACCOUNT_ID and $AWS_REGION from build.env
      - ECR_REGISTRY_URI="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
      - REPOSITORY_NAME="${SERVICE_NAME}"
      - BUILD_TAG="${BUILDKITE_COMMIT}"
      - IMAGE_URI="${ECR_REGISTRY_URI}/${REPOSITORY_NAME}"

      # Login, Build, and Push
      # Note: We use the shell variable $AWS_REGION here
      - aws ecr get-login-password --region ${AWS_REGION} | docker login --username AWS --password-stdin ${ECR_REGISTRY_URI}
      - docker build -t ${IMAGE_URI}:${BUILD_TAG} .
      - docker push ${IMAGE_URI}:${BUILD_TAG}

    # Store key variables as metadata for downstream pipelines
    env:
      IMAGE_URI: "${IMAGE_URI}"
      BUILD_TAG: "${BUILD_TAG}"
      # Also store the dynamic AWS variables if the next pipelines need them
      AWS_REGION: "$$(buildkite-agent meta-data get AWS_REGION)"
      AWS_ACCOUNT_ID: "$$(buildkite-agent meta-data get AWS_ACCOUNT_ID)"

  # --- 3. TRIGGER S3 PUSH PIPELINE (Optional Input + Trigger) ---
  - label: "‚ùì Trigger S3 Asset Push?"
    key: "ask_s3_push"
    prompt: "Do you want to extract and push the static assets to S3?"
    type: input
    depends_on: "build_and_push"
    fields:
      - text: "S3_CHOICE"
        default: "yes"
        options:
          - label: "Yes, push to S3"
            value: "yes"
          - label: "No, skip S3 push"
            value: "no"

  - label: "‚¨ÜÔ∏è Trigger S3 Push Pipeline"
    key: "trigger_s3"
    trigger: "my-s3-pipeline"
    build:
      # Pass required information to the triggered pipeline
      env:
        SERVICE_NAME: "$$(buildkite-agent meta-data get SERVICE_NAME)"
        IMAGE_URI: "$$(buildkite-agent meta-data get IMAGE_URI)"
        BUILD_TAG: "$$(buildkite-agent meta-data get BUILD_TAG)"
        # Pass the region so the S3 script can use it
        AWS_REGION: "$$(buildkite-agent meta-data get AWS_REGION)"
    if: "$$(buildkite-agent meta-data get S3_CHOICE) == 'yes'"

# ... (The rest of the triggers remain the same)